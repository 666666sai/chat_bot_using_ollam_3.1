it's a basic chabot creation using langchain and ollama model 

here I'm follwing the steps
Step1:
    -->importing required librarys
    -->create function(question_answering): it will return answer for questioning your model
        -->load model, prompttemplate
        -->create a prompt using prompttemplate
        -->provide prompt(input) to model
        --> return output generated by model
Step2:
    -->create input box using streamlit and submit button
    -->after submitting query then send this query to question_answering function 
    -->get output from question_answering function show as output using streamlit in front end



